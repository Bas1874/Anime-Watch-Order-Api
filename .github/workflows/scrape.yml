# .github/workflows/scrape.yml (Final, Robust Version)
name: Scrape Reddit Wiki and Push to Data Repo

on:
  schedule:
    - cron: '0 6 * * *' # Runs daily at 6:00 AM UTC
  workflow_dispatch: # Allows manual runs

jobs:
  scrape-and-deploy:
    runs-on: ubuntu-latest
    steps:
      - name: Checkout Scraper Repo
        uses: actions/checkout@v4

      - name: Checkout Data Repo
        uses: actions/checkout@v4
        with:
          repository: Bas1874/Watch-Order-Seanime # Your public data repository
          path: data-repo
          ssh-key: ${{ secrets.DEPLOY_KEY }}

      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.x'

      - name: Install dependencies
        run: pip install requests

      - name: Run Scraper
        env:
          REDDIT_CLIENT_ID: ${{ secrets.REDDIT_CLIENT_ID }}
          REDDIT_CLIENT_SECRET: ${{ secrets.REDDIT_CLIENT_SECRET }}
          REDDIT_USERNAME: ${{ secrets.REDDIT_USERNAME }}
          REDDIT_PASSWORD: ${{ secrets.REDDIT_PASSWORD }}
        run: python scrape_wiki.py ./data-repo/watch_order.json

      # --- THIS IS THE CORRECTED STEP ---
      - name: Commit and Push to Data Repo
        uses: stefanzweifel/git-auto-commit-action@v5
        with:
          # This tells the action to operate inside the 'data-repo' subfolder
          repository: ./data-repo
          commit_message: "Automated: Updated watch order data"
          # This specifies exactly which file to commit
          file_pattern: watch_order.json
